{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, auc, cohen_kappa_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.misc import derivative\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***some notes***\n",
    "\n",
    "I've also tried next techniques, like\n",
    "- under and oversampling (like SMOTE, ADASYN, ..)\n",
    "- as well as dimensionality reduction (PCA)\n",
    "- as well as feature selection (SelectKBest by chi2)\n",
    "- as well as removing outliers (with IsolationForest)\n",
    "\n",
    "but they didn't improve the quality of this specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_train_test(x_train, x_test, scaler, columns_to_scale):\n",
    "    # fit standard scaler only on train data\n",
    "    scaler.fit(x_train[columns_to_scale])\n",
    "\n",
    "    # transform train and test columns with scaler\n",
    "    x_train_scaled = scaler.transform(x_train[columns_to_scale])\n",
    "    x_test_scaled = scaler.transform(x_test[columns_to_scale])\n",
    "\n",
    "    # update x values with transformed ones\n",
    "    x_train.loc[:,columns_to_scale] = x_train_scaled\n",
    "    x_test.loc[:,columns_to_scale] = x_test_scaled\n",
    "\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>relative_timestamp</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>...</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "      <th>F29</th>\n",
       "      <th>F30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>118.44</td>\n",
       "      <td>159609.0</td>\n",
       "      <td>1.928977</td>\n",
       "      <td>-0.745709</td>\n",
       "      <td>-1.742981</td>\n",
       "      <td>-0.247731</td>\n",
       "      <td>-0.379232</td>\n",
       "      <td>-1.504379</td>\n",
       "      <td>0.426988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096171</td>\n",
       "      <td>0.153526</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.631590</td>\n",
       "      <td>0.130582</td>\n",
       "      <td>0.758711</td>\n",
       "      <td>-0.113741</td>\n",
       "      <td>-0.063939</td>\n",
       "      <td>0.795595</td>\n",
       "      <td>-2.200074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>162525.0</td>\n",
       "      <td>2.060450</td>\n",
       "      <td>-0.136926</td>\n",
       "      <td>-1.085910</td>\n",
       "      <td>0.430300</td>\n",
       "      <td>-0.254977</td>\n",
       "      <td>-1.247417</td>\n",
       "      <td>0.104193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302288</td>\n",
       "      <td>-0.795267</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>0.013651</td>\n",
       "      <td>-0.340015</td>\n",
       "      <td>0.199361</td>\n",
       "      <td>-0.078557</td>\n",
       "      <td>-0.062377</td>\n",
       "      <td>0.921937</td>\n",
       "      <td>0.216959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>58956.0</td>\n",
       "      <td>1.114014</td>\n",
       "      <td>-1.533296</td>\n",
       "      <td>0.741385</td>\n",
       "      <td>-1.385897</td>\n",
       "      <td>-1.241643</td>\n",
       "      <td>1.088519</td>\n",
       "      <td>-1.433041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140363</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.082555</td>\n",
       "      <td>-0.615175</td>\n",
       "      <td>-0.036441</td>\n",
       "      <td>-0.006456</td>\n",
       "      <td>0.109368</td>\n",
       "      <td>0.032635</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>-2.467540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>16.70</td>\n",
       "      <td>148842.0</td>\n",
       "      <td>0.514410</td>\n",
       "      <td>1.389934</td>\n",
       "      <td>-1.091181</td>\n",
       "      <td>1.604760</td>\n",
       "      <td>0.460984</td>\n",
       "      <td>-0.381953</td>\n",
       "      <td>-0.599145</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.670931</td>\n",
       "      <td>-0.854670</td>\n",
       "      <td>0.130428</td>\n",
       "      <td>0.789378</td>\n",
       "      <td>0.909599</td>\n",
       "      <td>-0.692159</td>\n",
       "      <td>-0.033316</td>\n",
       "      <td>0.096833</td>\n",
       "      <td>0.586722</td>\n",
       "      <td>1.187643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>110.14</td>\n",
       "      <td>125542.0</td>\n",
       "      <td>-0.849330</td>\n",
       "      <td>0.399191</td>\n",
       "      <td>-0.319642</td>\n",
       "      <td>-1.220384</td>\n",
       "      <td>1.062371</td>\n",
       "      <td>1.752440</td>\n",
       "      <td>0.558836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134113</td>\n",
       "      <td>0.278606</td>\n",
       "      <td>0.198983</td>\n",
       "      <td>-0.936208</td>\n",
       "      <td>-0.477630</td>\n",
       "      <td>-0.087217</td>\n",
       "      <td>0.035566</td>\n",
       "      <td>0.090183</td>\n",
       "      <td>0.569712</td>\n",
       "      <td>-1.485808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fraud  transaction_amount  relative_timestamp        F1        F2  \\\n",
       "0         0              118.44            159609.0  1.928977 -0.745709   \n",
       "1         0                1.98            162525.0  2.060450 -0.136926   \n",
       "2         0              103.00             58956.0  1.114014 -1.533296   \n",
       "3         0               16.70            148842.0  0.514410  1.389934   \n",
       "4         0              110.14            125542.0 -0.849330  0.399191   \n",
       "\n",
       "         F3        F4        F5        F6        F7  ...       F21       F22  \\\n",
       "0 -1.742981 -0.247731 -0.379232 -1.504379  0.426988  ... -0.096171  0.153526   \n",
       "1 -1.085910  0.430300 -0.254977 -1.247417  0.104193  ... -0.302288 -0.795267   \n",
       "2  0.741385 -1.385897 -1.241643  1.088519 -1.433041  ...  0.140363  0.783574   \n",
       "3 -1.091181  1.604760  0.460984 -0.381953 -0.599145  ... -1.670931 -0.854670   \n",
       "4 -0.319642 -1.220384  1.062371  1.752440  0.558836  ...  0.134113  0.278606   \n",
       "\n",
       "        F23       F24       F25       F26       F27       F28       F29  \\\n",
       "0 -0.001283  0.631590  0.130582  0.758711 -0.113741 -0.063939  0.795595   \n",
       "1  0.355477  0.013651 -0.340015  0.199361 -0.078557 -0.062377  0.921937   \n",
       "2  0.082555 -0.615175 -0.036441 -0.006456  0.109368  0.032635  0.225000   \n",
       "3  0.130428  0.789378  0.909599 -0.692159 -0.033316  0.096833  0.586722   \n",
       "4  0.198983 -0.936208 -0.477630 -0.087217  0.035566  0.090183  0.569712   \n",
       "\n",
       "        F30  \n",
       "0 -2.200074  \n",
       "1  0.216959  \n",
       "2 -2.467540  \n",
       "3  1.187643  \n",
       "4 -1.485808  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df_path = './data/df.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split on features and target \n",
    "X = df.drop('is_fraud', axis=1)\n",
    "Y = df['is_fraud']\n",
    "\n",
    "# columns F29 and F30 have missing values, fill na with mean\n",
    "X.fillna(X.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# focal loss\n",
    "Focal loss was designed for object detection purpose, where there is  extreme foreground-background class imbalance.\n",
    "\n",
    "https://arxiv.org/pdf/1708.02002.pdf\n",
    "\n",
    "inspired by https://towardsdatascience.com/lightgbm-with-the-focal-loss-for-imbalanced-datasets-9836a9ae00ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_lgb(y_true, y_pred, alpha, gamma):\n",
    "    a,g = alpha, gamma\n",
    "    def fl(x,t):\n",
    "        p = 1/(1+np.exp(-x))\n",
    "        return -( a*t + (1-a)*(1-t) ) * (( 1 - ( t*p + (1-t)*(1-p)) )**g) * ( t*np.log(p) + (1-t)*np.log(1-p) )\n",
    "    partial_fl = lambda x: fl(x, y_true)\n",
    "    grad = derivative(partial_fl, y_pred, n=1, dx=1e-6)\n",
    "    hess = derivative(partial_fl, y_pred, n=2, dx=1e-6)\n",
    "    return grad, hess\n",
    "\n",
    "def focal_loss_lgb_eval_error(y_true, y_pred, alpha, gamma):\n",
    "    a,g = alpha, gamma\n",
    "    p = 1/(1+np.exp(-y_pred))\n",
    "    loss = -( a*y_true + (1-a)*(1-y_true) ) * (( 1 - ( y_true*p + (1-y_true)*(1-p)) )**g) * ( y_true*np.log(p)+(1-y_true)*np.log(1-p) )\n",
    "    return 'focal_loss', np.mean(loss), False\n",
    "\n",
    "\n",
    "alpha=0.25\n",
    "gamma=1.\n",
    "\n",
    "focal_loss = lambda x,y: focal_loss_lgb(x, y, alpha=alpha, gamma=gamma)\n",
    "focal_loss_eval = lambda x,y: focal_loss_lgb_eval_error(x, y, alpha=alpha, gamma=gamma)\n",
    "\n",
    "def sigmoid(x): return 1./(1. +  np.exp(-x))\n",
    "\n",
    "\n",
    "class FocalLGBMClassifier(lgb.LGBMClassifier):\n",
    "    \n",
    "    def predict_proba(self, *args, **kwargs):\n",
    "        \"\"\"Redefining predict_proba(), because when using custom loss function, \n",
    "        the raw predictions are not passed through a sigmoid to represent probabilitie\n",
    "        \"\"\"\n",
    "        result = super().predict_proba(*args, **kwargs)\n",
    "        return sigmoid(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LGBMClassifier with focal loss\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "f1_scores = []\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    x_train, x_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = Y.loc[train_index], Y.loc[test_index]\n",
    "    \n",
    "    # scale features\n",
    "    scaler = StandardScaler()\n",
    "    columns_to_scale = ['transaction_amount','relative_timestamp']\n",
    "    x_train, x_test = scale_train_test(x_train, x_test, scaler, columns_to_scale)\n",
    "    \n",
    "    # train a model\n",
    "    model = FocalLGBMClassifier(\n",
    "        num_leaves = 70,\n",
    "        n_estimators = 100,\n",
    "        random_state = 42,\n",
    "        class_weight='balanced', \n",
    "        objective = focal_loss) # or objective='binary' \n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    f1_scores.append(f1)\n",
    "    scores.append((p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9058823529411765, 0.7777777777777778, 0.8369565217391305),\n",
       " (0.9058823529411765, 0.7777777777777778, 0.8369565217391305),\n",
       " (0.9512195121951219, 0.7959183673469388, 0.8666666666666666),\n",
       " (0.9753086419753086, 0.8061224489795918, 0.88268156424581),\n",
       " (0.9021739130434783, 0.8469387755102041, 0.8736842105263158)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(round(np.mean(f1_scores),2))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutliersTransformer():    \n",
    "    def __init__(self, features, coef=3):\n",
    "        self.features = features\n",
    "        self.coef = coef\n",
    "        self.boundaries = {}\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        # define upper and lower boundaries for each feature \n",
    "        # by non-fraud transactions only\n",
    "        for f in self.features:        \n",
    "            x_0 = x[y == 0]\n",
    "            lower, upper = self.iqr_outliers_boundaries(x_0[f], self.coef)\n",
    "            self.boundaries[f]=(lower, upper)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, y=None):   \n",
    "        # update outliers values\n",
    "        # at non-fraud transactions only\n",
    "        if y is not None:\n",
    "            for f in self.features: \n",
    "                lower, upper = self.boundaries[f]\n",
    "                x_0 = x[y == 0]\n",
    "                update_index = x.loc[x_0.index].loc[(x[f]<lower)|(x[f]>upper)].index\n",
    "                x.loc[update_index, f] = (lower + upper) / 2\n",
    "        return x\n",
    "    \n",
    "    def iqr_outliers_boundaries(self, data, coef=3):\n",
    "        # calculate interquartile range\n",
    "        q25, q75 = np.percentile(data, 25), np.percentile(data, 75)\n",
    "        iqr = q75 - q25\n",
    "\n",
    "        # calculate the outlier cutoff\n",
    "        cut_off = iqr * coef\n",
    "        lower, upper = q25 - cut_off, q75 + cut_off\n",
    "        return lower, upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble \n",
    "- LGBMClassifier + focal loss \n",
    "- LogisticRegression + remove ouliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Voting Classifier\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "f1_scores = []\n",
    "scores = []\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    x_train, x_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = Y.loc[train_index], Y.loc[test_index]\n",
    "    \n",
    "    # scale features\n",
    "    scaler = StandardScaler()\n",
    "    columns_to_scale = ['transaction_amount','relative_timestamp']\n",
    "    x_train, x_test = scale_train_test(x_train, x_test, scaler, columns_to_scale)\n",
    "    \n",
    "    # build and train the model\n",
    "    clf1 = FocalLGBMClassifier(\n",
    "        num_leaves = 70,\n",
    "        n_estimators = 100,\n",
    "        random_state = 42,\n",
    "        class_weight='balanced', \n",
    "        objective = focal_loss)\n",
    "    \n",
    "    corr_features = ['F4', 'F10', 'F11', 'F12', 'F14']\n",
    "    clf2 = Pipeline(steps=[('outliers', OutliersTransformer(corr_features, 3)),\n",
    "                           ('model', LogisticRegression())])\n",
    "    \n",
    "    voting = VotingClassifier(estimators=[('lgb', clf1), ('lr', clf2)], voting='soft', weights=(0.9,0.1))\n",
    "    voting = voting.fit(x_train, y_train)\n",
    "    \n",
    "    # make prediction\n",
    "    y_pred = voting.predict(x_test)\n",
    "    \n",
    "    # evaluate the quality\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    f1_scores.append(f1)\n",
    "    scores.append((p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.9294117647058824, 0.797979797979798, 0.8586956521739131),\n",
       " (0.9285714285714286, 0.7878787878787878, 0.8524590163934426),\n",
       " (0.9629629629629629, 0.7959183673469388, 0.871508379888268),\n",
       " (0.9625, 0.7857142857142857, 0.8651685393258427),\n",
       " (0.9111111111111111, 0.8367346938775511, 0.8723404255319148)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(round(np.mean(f1_scores),2))\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=13, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['transaction_amount','relative_timestamp']\n",
    "x_train, x_test = scale_train_test(x_train, x_test, scaler, columns_to_scale)\n",
    "    \n",
    "# build the model\n",
    "clf1 = FocalLGBMClassifier(\n",
    "        random_state = 42,\n",
    "        class_weight='balanced', \n",
    "        objective = focal_loss)\n",
    "    \n",
    "corr_features = ['F4', 'F10', 'F11', 'F12', 'F14']\n",
    "clf2 = Pipeline(steps=[('outliers', OutliersTransformer(corr_features, 3)),\n",
    "                           ('model', LogisticRegression())])\n",
    "    \n",
    "voting = VotingClassifier(estimators=[('lgb', clf1), ('lr', clf2)], voting='soft', weights=(0.9,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'outliers', 'model', 'model__C', 'model__class_weight', 'model__dual', 'model__fit_intercept', 'model__intercept_scaling', 'model__l1_ratio', 'model__max_iter', 'model__multi_class', 'model__n_jobs', 'model__penalty', 'model__random_state', 'model__solver', 'model__tol', 'model__verbose', 'model__warm_start'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boosting_type', 'class_weight', 'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth', 'min_child_samples', 'min_child_weight', 'min_split_gain', 'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin', 'subsample_freq'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid search model parameters\n",
    "grid_params = {'lr__model__C' : [0.5,1,1.5], \n",
    "               'lr__model__penalty': ['l1', 'l2'],\n",
    "               'lgb__n_estimators':[100,150], \n",
    "               'lgb__num_leaves':[30,70]}\n",
    "grid = GridSearchCV(estimator=voting, param_grid=grid_params, cv=2, scoring='f1_weighted', n_jobs=-1)\n",
    "grid = grid.fit(x_train, y_train)\n",
    "\n",
    "# model with best parameters\n",
    "estimator = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(estimator.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "estimator = estimator.fit(x_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "y_pred = estimator.predict(x_test)\n",
    "y_scores = estimator.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics and curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the quality\n",
    "p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "# check roc_curve \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "# plot ROC\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.0])\n",
    "plt.ylim([-0.1,1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.98      0.82      0.89        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.91      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen’s kappa coefficient is 0.89\n"
     ]
    }
   ],
   "source": [
    "coef = cohen_kappa_score(y_test, y_pred)\n",
    "print(f\"Cohen’s kappa coefficient is {coef:.2f}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
